# Movies-ETL

## Project Overview
I will be learning how to Extract, Transform, and Load (ETL) to create data pipelines. I will be:
  - Creating an ETL pipeline from raw data to a SQL database.
  - Extract data from disparate sources using Python.
  - Clean and transform data using Pandas.
  - Using regular expressions to parse data and to transform text into numbers.
  - Loading data with PostgrSQL.

## Resources
- Data Source: movies_metadata.csv, ratings.csv, wikipedia.movies.json
- Software: SQL, pgAdmin 4, PostgresSQL, VS Code, Python

## Challenge Overview
In this challenge, I will be writing a Python script that performs all three ETL steps on the Wikipedia and Kaggle data. While ETL can absolutely be used for a one-time transfer of data, it becomes really powerful when it can be automated as a repeated, ongoing process.

The goals for this challenge are:
  1. Create an automated ETL pipeline.
  2. Extract data from multiple sources.
  3. Clean and transform the data automatically using Pandas and regular expressions.
  4. Load new data into PostgreSQL.

## Challenge Summary
